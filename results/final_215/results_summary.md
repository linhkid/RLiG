# Model Evaluation Results Summary

## Overview

- Total datasets evaluated: 15
- Total models compared: 8
- Overall average performance: 0.5939

## Model Rankings

| Rank | Model | Average Score |
|------|-------|---------------|
| 1 | RLIG | 0.7759 |
| 2 | GANBLR++ | 0.7700 |
| 3 | GANBLR | 0.7502 |
| 4 | NB | 0.5981 |
| 5 | DIST_SAMPL | 0.5590 |
| 6 | CTABGAN | 0.5417 |
| 7 | CTGAN | 0.4833 |
| 8 | GREAT | 0.2729 |

## Top Performing Model-Classifier Combinations

| Rank | Model-Classifier | Average Score |
|------|-----------------|---------------|
| 1 | RLIG-LR | 0.7875 |
| 2 | GANBLR++-LR | 0.7826 |
| 3 | GANBLR++-MLP | 0.7745 |
| 4 | GANBLR++-XGB | 0.7712 |
| 5 | RLIG-RF | 0.7709 |
| 6 | RLIG-MLP | 0.7694 |
| 7 | GANBLR-LR | 0.7678 |
| 8 | GANBLR++-RF | 0.7574 |
| 9 | GANBLR-XGB | 0.7545 |
| 10 | GANBLR-MLP | 0.7506 |

## Dataset Performance

Best performing model for each dataset:

| Dataset | Best Model | Score |
|---------|------------|-------|
| Adult | GANBLR++ | 0.5383 |
| Car | RLIG | 0.8825 |
| Chess | GANBLR++ | 0.9431 |
| Connect-4 | GANBLR++ | 0.7486 |
| covtype | GANBLR++ | 0.6908 |
| Credit | RLIG | 0.8007 |
| Default | GANBLR | 0.8129 |
| letter_recog | GANBLR++ | 0.6324 |
| Magic | GANBLR++ | 0.7980 |
| Maternal_Health | RLIG | 0.6968 |
| NSL-KDD | RLIG | 0.8854 |
| Nursery | RLIG | 0.9013 |
| Rice | RLIG | 0.8788 |
| Room_Occupancy | GANBLR | 0.9966 |
| TicTacToe | RLIG | 0.7014 |
